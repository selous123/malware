#coding:utf-8
import tensorflow as tf

def lazy_property(func):
    attr_name = "_lazy_" + func.__name__
    @property
    def _lazy_property(self):
        if not hasattr(self, attr_name):
            setattr(self, attr_name, func(self))
        return getattr(self, attr_name)
    return _lazy_property


class malwareModel(object):
    def __init__(self,images,labels,learning_rate=0.1,\
                 height=128,width=128,num_classes=9,one_hot=True):
        """
        Args:
            labels：必须是one_hot编码,shape;[batch_size,num_classes]
            images：shape;[batch_size,columns*rows](assuming depth=1)
            height:
            width:
            num_classes:
        """
        self._images = images
        self._height = height
        self._width = width
        self._num_classes = num_classes
        self._labels = labels
        self._logits = None
        self._optimize = None
        self._learning_rate =learning_rate 
        self._accuracy = None
        self._prob = None
        
    @lazy_property
    def prediction(self):
        """
        Return:
            self._logits:shape;[batch_size,num_classes]
        """
        
        with tf.variable_scope("input"):
            images = tf.reshape(self._images,shape=[-1,self._height,self._width,1],name="reshape")
            
        with tf.variable_scope("conv1"):
            weights = tf.get_variable("weights",shape=[5,5,1,32],\
                                      initializer=tf.truncated_normal_initializer(stddev=0.01))
            bias = tf.get_variable("bias",shape = [32],\
                                   initializer=tf.constant_initializer(0.1))
            conv1 = tf.nn.relu(tf.nn.conv2d(images,weights,\
                                            strides=[1,1,1,1],padding='SAME')+bias,name="relu1")
        with tf.variable_scope("pool1"):
            pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')
            
        with tf.variable_scope('conv2'):
            weight = tf.get_variable("weight",shape=[5,5,32,64],initializer=tf.truncated_normal_initializer(stddev=0.01));
            bias = tf.get_variable("bias",shape = [64],initializer=tf.constant_initializer(0.1));
            conv2 = tf.nn.relu(tf.nn.conv2d(pool1,weight,strides=[1, 1, 1, 1], padding='SAME')+bias)
        
        with tf.variable_scope('pool2'):
            pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')
    
    
    
        with tf.variable_scope('nn1'):
            pool2_flat = tf.reshape(pool2,[-1,32*32*64]);
            weight = tf.get_variable("weights",shape = [32*32*64,1024],\
                                     initializer=tf.truncated_normal_initializer(stddev = 0.01));
            bias = tf.get_variable("bias",shape=[1024],initializer=tf.constant_initializer(0.1));
            nn1_output = tf.nn.tanh(tf.matmul(pool2_flat,weight)+bias);
    
        
        with tf.variable_scope("softmax_layer"):
            weights = tf.get_variable("weights",shape=[1024,1]\
                                      ,initializer=tf.truncated_normal_initializer(stddev=0.01))
            bias = tf.get_variable("bias",shape=[1],dtype=tf.float32,initializer=tf.constant_initializer(0.1))
            _prob =  tf.matmul(nn1_output,weights)+bias
            self._logits = tf.nn.sigmoid(_prob)
        return _prob
    @lazy_property
    def optimize(self):
        #loss = -tf.reduce_mean(self._labels*tf.log(self.prediction))
        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=self._labels,logits=self.prediction)
        
        tf.summary.scalar('loss',loss)
        optimizer = tf.train.AdamOptimizer(self._learning_rate)
        self._optimize = optimizer.minimize(loss)
        return loss,self._optimize
        
#==============================================================================
#     def accuracy(self):
#         from sklearn.metrics import f1_score
#         logits = tf.cast(tf.greater(self._logits,0.5),tf.float32)
#         return f1_score(self._labels,logits)
#         correct_prediction= tf.equal(tf.cast(tf.greater(self._logits,0.5),tf.float32),self._labels)
#         self._accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
#         return self._accuracy
#==============================================================================
from sklearn.metrics import f1_score
import numpy as np
def accuracy(labels,logits):
    """
    Args:
        labels:[batch_size,1]
        logits:[batch_size,1],probability of 1
    """
    logits = (np.array(logits)>0).astype(int)
    return f1_score(labels,logits,average='weighted')
    
    
    
    
    
    
    
    
    
    
    
    
    
    