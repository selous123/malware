#coding:utf-8
from __future__ import division
from collections import namedtuple
import numpy as np
np.set_printoptions(threshold=1e6)
DataSets = namedtuple("DataSets",["train","validation","test"])



#def train_test_split(images,labels,test_size)
class DataSet(object):
    def __init__(self,images,labels,num_classes=9,one_hot=True,reshape=True):
        """
        Args:
            one_hot:convert labels from number to 0-1 code.
            reshape:convert images from [num_examples,rows,columns,depth]
                to shape [num_examples,row*columns](assuming depth=1)
        """
#==============================================================================
#         #one_hot
#         if one_hot==True:
#             labels = denseToOneHot(labels,num_classes)
#==============================================================================
        #reshape
        if reshape:
            images = images.reshape(images.shape[0],images.shape[1]*images.shape[2])
            labels = labels.reshape(-1,1)
        self._images = images
        self._labels = labels
        self._epoch_completed = 0
        self._index_in_epoch = 0
    @property
    def images(self):
        return self._images
    
    @property
    def labels(self):
        return self._labels
    
    @property
    def num_examples(self):
        return self._images.shape[0]

    @property
    def epoches_completed(self):
        return self._epoches_completed
    
    def next_batch(self,batch_size):
        start = self._index_in_epoch
        self._index_in_epoch += batch_size
        if self._index_in_epoch > self.num_examples:
            self._epoch_completed+=1
            #shuffle data
            perm = np.arange(self.num_examples)
            np.random.shuffle(perm)
            self._images = self._images[perm]
            self._labels = self._labels[perm]
            #start next epoch
            start = 0
            self._index_in_epoch = batch_size
        end = self._index_in_epoch
        return self._images[start:end],self._labels[start:end]

import os
import cv2
from sklearn.model_selection import train_test_split
size = 128,128
def read_data_sets(dirpaths):
    #list all file name in the folder dir.
    images = np.empty(shape=[0,128,128])
    labels = np.empty(shape=[0])
    for label,dirPath in enumerate(dirpaths):
        paths = os.listdir(dirPath)
        images_tmp = np.zeros([len(paths),128,128],dtype=np.float32)
        labels_tmp = np.zeros([len(paths)],dtype=np.int32)
        for ind,path in enumerate(paths):
            images_tmp[ind] = cv2.resize(cv2.imread(dirPath+path,cv2.IMREAD_GRAYSCALE),(128,128))/256
            labels_tmp[ind] = label
            if ind%1000==0:
                print "ind is {}".format(ind)
        images = np.concatenate((images,images_tmp),axis=0)
        labels = np.concatenate((labels,labels_tmp),axis=0)
    #print labels
    images_train,images_test,labels_train,labels_test = \
    train_test_split(images,labels,test_size=0.2,stratify=labels)

    #print labels_test
    train = DataSet(images_train,labels_train)
    test = DataSet(images_test,labels_test)
    
    #print test.labels
    
    return DataSets(train=train,validation=None,test=test)
    
        

def load_malware(dirpaths):
    return read_data_sets(dirpaths)
 
        
    
if __name__=="__main__":
    

    """
    path = "img/"
    data_set = load_malware(path)
    
    print data_set.train.images.shape
    print data_set.train.labels.shape
    
    images,labels= data_set.train.next_batch(128)

    print images[0]

    """
    dirpaths = ["/mnt/hgfs/ubuntu14/dataset/2017-05-09_av_test/img/pua/","/mnt/hgfs/ubuntu14/dataset/2017-05-09_av_test/img/normal/"]
    
    data = load_malware(dirpaths)
    images,labels = data.train.next_batch(128)
    print labels
    
    
    
    
    
    
    
    
    
    
    