#coding:utf-8
from __future__ import division
from collections import namedtuple
import numpy as np
np.set_printoptions(threshold=1e6)
DataSets = namedtuple("DataSets",["train","validation","test"])

def lazy_property(func):
    attr_name = "_lazy_" + func.__name__
    @property
    def _lazy_property(self):
        if not hasattr(self, attr_name):
            setattr(self, attr_name, func(self))
        return getattr(self, attr_name)
    return _lazy_property

#def train_test_split(images,labels,test_size)
class TrainDataSet(object):
    def __init__(self,pua_images,normal_images,normal_proportion=1,\
                 num_classes=2,one_hot=True,reshape=True):
        """
        Args:
            one_hot:convert labels from number to 0-1 code.
            reshape:convert images from [num_examples,rows,columns,depth]
                to shape [num_examples,row*columns](assuming depth=1)
            normal_proportion:proportion of pua images and normal images per batch
            pua:normal = 1:normal_proportion
        """
#==============================================================================
#         #one_hot
#         if one_hot==True:
#             labels = denseToOneHot(labels,num_classes)
#==============================================================================
        #reshape
        if reshape:
            pua_images = pua_images.reshape(-1,pua_images.shape[1]*pua_images.shape[2])
            normal_images =normal_images.reshape(-1,normal_images.shape[1]*normal_images.shape[2])
        self._pua_images = pua_images
        self._normal_images = normal_images
        self._pua_epoch_completed = 0
        self._pua_index_in_epoch = 0
        self._normal_epoch_completed = 0
        self._normal_index_in_epoch = 0
        self._normal_proportion = normal_proportion
    @property
    def pua_images(self):
        return self._pua_images
    
    @property
    def normal_images(self):
        return self._normal_images
    
    @property
    def num_pua_images(self):
        return self._pua_images.shape[0]
    
    @property
    def num_normal_images(self):
        return self._normal_images.shape[0]
    
    @property
    def pua_epoches_completed(self):
        return self._pua_epoches_completed
    @property
    def normal_epoches_completed(self):
        return self._normal_epoches_completed
    
    def pua_normal_num(self,batch_size):
        normal_num = int((batch_size*self._normal_proportion)//(self._normal_proportion+1))
        pua_num = batch_size - normal_num
        return normal_num,pua_num
    
# =============================================================================
#     def nex_batch(self,batch_size):
#         if self._is_train:
#             return self._train_next_batch(batch_size)
#         else:
#             return self._test_next_batch(batch_size)
# =============================================================================
    
    def next_batch(self,batch_size):
        #define labels
        labels = np.zeros(shape=[batch_size,1])
        normal_num,pua_num = self.pua_normal_num(batch_size)
        #pua images
        pua_start = self._pua_index_in_epoch
        self._pua_index_in_epoch += pua_num
        if self._pua_index_in_epoch > self.num_pua_images:
            self._pua_epoch_completed +=1
            perm = np.arange(self.num_pua_images)
            np.random.shuffle(perm)
            self._pua_images = self._pua_images[perm]
            pua_start = 0
            self._pua_index_in_epoch = pua_num
        pua_end = self._pua_index_in_epoch
        pua_images = self.pua_images[pua_start:pua_end]
        
        #normal images
        normal_start = self._normal_index_in_epoch
        self._normal_index_in_epoch += normal_num
        if self._normal_index_in_epoch > self.num_normal_images:
            self._normal_epoch_completed +=1
            perm = np.arange(self.num_normal_images)
            np.random.shuffle(perm)
            self._normal_images = self._normal_images[perm]
            normal_start = 0
            self._normal_index_in_epoch = normal_num
        normal_end = self._normal_index_in_epoch
        normal_images = self.normal_images[normal_start:normal_end]
        
        #concatenate
        images = np.concatenate((pua_images,normal_images),axis=0)
        labels[pua_num:] = 1
        
        perm = np.arange(batch_size)
        np.random.shuffle(perm)
        images = images[perm]
        labels = labels[perm]
        return images,labels
        
    
class TestDataSet(object):
    def __init__(self,images,labels,num_classes=9,one_hot=True,reshape=True):
        """
        Args:
            one_hot:convert labels from number to 0-1 code.
            reshape:convert images from [num_examples,rows,columns,depth]
                to shape [num_examples,row*columns](assuming depth=1)
        """
        #reshape
        if reshape:
            images = images.reshape(images.shape[0],images.shape[1]*images.shape[2])
        self._images = images
        self._labels = labels
        self._epoch_completed = 0
        self._index_in_epoch = 0
    @property
    def images(self):
        return self._images
    
    @property
    def labels(self):
        return self._labels
    
    @property
    def num_examples(self):
        return self._images.shape[0]

    @property
    def epoches_completed(self):
        return self._epoches_completed
    
    def next_batch(self,batch_size):
        start = self._index_in_epoch
        self._index_in_epoch += batch_size
        if self._index_in_epoch > self.num_examples:
            self._epoch_completed+=1
            #shuffle data
            perm = np.arange(self.num_examples)
            np.random.shuffle(perm)
            self._images = self._images[perm]
            self._labels = self._labels[perm]
            #start next epoch
            start = 0
            self._index_in_epoch = batch_size
        end = self._index_in_epoch
        return self._images[start:end],self._labels[start:end]        

import os
import cv2
#from sklearn.model_selection import train_test_split
size = 128,128
def read_data_sets(dirpaths):
    #list all file name in the folder dir.
    #images = np.empty(shape=[0,128,128])
    #labels = np.empty(shape=[0])
    
    pua_path,normal_path = dirpaths
    paths = os.listdir(pua_path)
    pua_images = np.zeros([len(paths),128,128],dtype=np.float32)
    for ind,path in enumerate(paths):
        pua_images[ind] = cv2.resize(cv2.imread(pua_path+path,cv2.IMREAD_GRAYSCALE),(128,128))/256
        if ind%1000==0:
            print "ind is {}".format(ind)
            
    paths = os.listdir(normal_path)
    normal_images = np.zeros([len(paths),128,128],dtype=np.float32)
    for ind,path in enumerate(paths):
        normal_images[ind] = cv2.resize(cv2.imread(normal_path+path,cv2.IMREAD_GRAYSCALE),(128,128))/256
        if ind%1000==0:
            print "ind is {}".format(ind)
    
    
# =============================================================================
#     for label,dirPath in enumerate(dirpaths):
#         paths = os.listdir(dirPath)
#         images_tmp = np.zeros([len(paths),128,128],dtype=np.float32)
#         labels_tmp = np.zeros([len(paths)],dtype=np.int32)
#         for ind,path in enumerate(paths):
#             images_tmp[ind] = cv2.resize(cv2.imread(dirPath+path,cv2.IMREAD_GRAYSCALE),(128,128))/256
#             if ind%1000==0:
#                 print "ind is {}".format(ind)
#         images = np.concatenate((images,images_tmp),axis=0)
#         labels = np.concatenate((labels,labels_tmp),axis=0)
# =============================================================================
    #print labels
    test_size = 0.2
    test_pua_num = int(pua_images.shape[0]*test_size)
    test_normal_num = int(normal_images.shape[0]*test_size)
    pua_images_train = pua_images[test_pua_num:]
    pua_images_test = pua_images[0:test_pua_num]
    normal_images_train = normal_images[test_normal_num:]
    normal_images_test = normal_images[0:test_normal_num]
    #print labels_test
    ##train images
    train = TrainDataSet(pua_images_train,normal_images_train)
    
    ##test images
    test_images = np.concatenate((pua_images_test,normal_images_test),axis=0)
    test_labels = np.zeros(shape = (test_images.shape[0],1))
    test_labels[test_pua_num:,0] = 1
    test = TestDataSet(test_images,test_labels)
    
    #print test.labels
    
    return DataSets(train=train,validation=None,test=test)
    
        

def load_malware(dirpaths):
    return read_data_sets(dirpaths)
 
        
    
if __name__=="__main__":
    

    """
    path = "img/"
    data_set = load_malware(path)
    
    print data_set.train.images.shape
    print data_set.train.labels.shape
    
    images,labels= data_set.train.next_batch(128)

    print images[0]

    """
    #dirpaths = ["/home/lrh/dataset/malware/malware_img/pua/","/home/lrh/dataset/malware/malware_img/normal/"]
    dirpaths = ["/home/lrh/dataset/malware/malware_image/pua","/home/lrh/dataset/malware/malware_image/normal"]
    data = load_malware(dirpaths)
    images,labels = data.train.next_batch(128)
    print labels
    
    
    
    
    
    
    
    
    
    
    