from malware_model import malwareModel as model
from malware_model import accuracy
from load_malware import load_malware 
import sys
import argparse
import tensorflow as tf
import math
import numpy as np

FLAGS = None
image_height,image_width=128,128
PIXEL_NUM = image_height*image_width
NUM_CLASSES = 2
def train():

    ##prepare data
    input_data = load_malware(FLAGS.input_data_dir)

    #build the graph
    images_pl = tf.placeholder(tf.float32,shape=[None,PIXEL_NUM],name="images")
    labels_pl = tf.placeholder(tf.float32,shape=[None,1],name="labels")

    m = model(images_pl,labels_pl,FLAGS.learning_rate,image_height,image_width,NUM_CLASSES)
    loss,optimize= m.optimize
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    print update_ops
    with tf.control_dependencies(update_ops):
        optimize = tf.group(optimize)
    #prediction = m.prediction
    logits = m._logits
    summary_op = tf.summary.merge_all()
    init = tf.global_variables_initializer()
    ##build session
    session = tf.Session()
    session.run(init)
    summary_writer = tf.summary.FileWriter(FLAGS.log_dir,session.graph);
    
    ##run training data 
    for ind in range(FLAGS.max_step):
        images,labels = input_data.train.next_batch(FLAGS.batch_size)
        _,loss_curr,logits_curr= session.run([optimize,loss,logits],feed_dict={
            images_pl:images,
            labels_pl:labels
        })
        
        #tensorboard
        if ind%100==0:
            summary_str = session.run(summary_op, feed_dict={
                images_pl:images,
                labels_pl:labels
                })
            summary_writer.add_summary(summary_str, ind)
            summary_writer.flush()
        if ind%100==0:
            p_curr,r_curr = accuracy(labels,logits_curr)
            print "step:{},prediction accuracy:{},Recall acc:{},loss:{}".format(ind,p_curr,r_curr,loss_curr)
    
    
    #compute accuracy of test data.
# =============================================================================
#     num_steps = int(math.ceil((input_data.test.num_normal_images+input_data.test.num_pua_images) / FLAGS.batch_size))
#     p_acc = []
#     r_acc = []
#     for ind in range(num_steps):
#         images,labels = input_data.test.next_batch(80)
#         logits_curr = session.run([logits],feed_dict={
#                 images_pl:images,
#                 labels_pl:labels})
#         p_curr,r_curr = accuracy(labels,logits_curr)
#         p_acc.append(round(p_curr,3))
#         r_acc.append(round(r_curr,3))
#     print "test prediction is {0},the mean p accuracy is {1},recall is {2},mean r is{3}".\
#     format(p_acc,sum(p_acc)/len(p_acc),r_acc,sum(r_acc)/len(r_acc))
# =============================================================================
    
    
    ##compute accuracy another method
    images,labels = input_data.test.images,input_data.test.labels
    
    num_steps = int(math.ceil(images.shape[0] / FLAGS.batch_size))
    logits_sum = np.empty(shape=(0,1))
    for ind in range(num_steps):
        if ind==num_steps-1:
            end = images.shape[0]
        else:
            end = (ind+1) * FLAGS.batch_size
        logits_curr = session.run(logits,feed_dict={
                images_pl:images[ind*FLAGS.batch_size:end],
                labels_pl:labels[ind*FLAGS.batch_size:end]
                })
        logits_sum = np.concatenate((logits_sum,np.array(logits_curr)),axis=0)
    p_curr,r_curr = accuracy(labels,logits_sum)
    print "test accuracy {},test recall {}".format(p_curr,r_curr);
    
    
    
def main(_):
    if tf.gfile.Exists(FLAGS.log_dir):
        tf.gfile.DeleteRecursively(FLAGS.log_dir);
    tf.gfile.MakeDirs(FLAGS.log_dir);
    train();


if __name__=="__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--batch_size",
        type=int,
        default=128,
        help="size of batch"
        )
    parser.add_argument(
        "--input_data_dir",
        type=list,
        default=["/home/lrh/dataset/malware/malware_img/pua/","/home/lrh/dataset/malware/malware_img/normal/"],
        help="directory of input data")
    parser.add_argument(
        "--log_dir",
        type=str,
        default="/tmp/tensorflow/malware/logs",
        help="directory of log dir"
        )
    parser.add_argument(
        "--max_step",
        type=int,
        default=10000,
        help="max step"
        )
    parser.add_argument(
        "--learning_rate",
        type = float,
        default=0.0001,
        help="learning rate"
        )

    FLAGS,unparse = parser.parse_known_args();
    #hello world
    tf.app.run(main=main,argv=[sys.argv[0]]+unparse);
